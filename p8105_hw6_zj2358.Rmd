---
title: "p8105_hw6"
author: "Zhezheng Jin"
date: "2023-11-29"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
library(janitor)
library(readxl)
library(broom)
library(boot)
library(modelr)

opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Data import
```{r message=F}
homicide <- read_csv("./data_file/homicide-data.csv")

homicide
```

#### Data wrangling
```{r}
homicide_clean <- homicide %>%
  # Create city_state variable
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  # Omit specified cities
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) %>%
  # Limit analysis to white or black victim race
  filter(victim_race %in% c("White", "Black")) %>%
  # Create is_solved binary variable
  mutate(is_solved = if_else(disposition == "Closed by arrest", 1, 0)) %>%
  # Ensure victim_age is numeric
  mutate(victim_age = as.numeric(victim_age))

homicide_clean
```

#### Logistic regression analysis for Baltimore
```{r}
# Step 1: Filter data for Baltimore, MD
baltimore_data <- homicide_clean %>%
  filter(city_state == "Baltimore, MD")

# Step 2: Prepare data (ensure factors and binary outcome)
baltimore_data <- baltimore_data %>%
  mutate(victim_sex = as.factor(victim_sex),
         victim_race = as.factor(victim_race),
         is_solved = factor(is_solved, levels = c(0, 1)))

# Step 3: Fit logistic regression model
model <- glm(is_solved ~ victim_age + victim_sex + victim_race, 
             data = baltimore_data, family = binomial())

# Step 4: Apply broom::tidy to the model object
model_tidy <- tidy(model)

# Displaying the tidy model summary
print(model_tidy)

# Step 5: Calculate adjusted odds ratios 
adjusted_or <- exp(coef(model)["victim_sexMale"])  # For Male vs Female comparison
CI <- confint(model)  # Default confidence interval
CI_adjusted_or <- exp(CI["victim_sexMale", ])

# Displaying the adjusted odds ratio and its confidence interval
adjusted_or
CI_adjusted_or

```

The adjusted odds ratio of 0.426 suggests that, in Baltimore, MD, the odds of solving a homicide for male victims are 0.426 times the the odds of solving a homicide for female victims, when controlling for other factors. We are 95% confident that this true odds ratio lies between 0.324 and 0.558. The confidence interval reinforces this conclusion and indicates a statistically significant difference, as it does not include 1. 

#### GLM analysis for each city
```{r}
# Step 1 & 2: Group by city and nest data
nested_data <- homicide_clean %>%
  group_by(city_state) %>%
  nest()

# Step 3: Fit logistic regression model and tidy with confidence intervals for each city
nested_data <- nested_data %>%
  mutate(model = map(data, ~glm(is_solved ~ victim_age + victim_sex + victim_race, 
                                data = .x, family = binomial())),
         tidied = map(model, ~tidy(.x, conf.int = TRUE)))

# Step 4: Extract coefficients for `victim_sexMale`
nested_data <- nested_data %>%
  mutate(ORs = map(tidied, ~filter(.x, term == "victim_sexMale") %>%
                     mutate(OR = exp(estimate),
                            CI_lower = exp(conf.low),
                            CI_upper = exp(conf.high))))

# Step 5: Unnest and organize results
GLM_results <- nested_data %>%
  select(city_state, ORs) %>%
  unnest(ORs) %>%
  select(city_state, OR, CI_lower, CI_upper)

GLM_results
```

#### Plot: GLM analysis for each city
```{r}
GLM_results <- GLM_results %>%
  arrange(OR)

GLM_plot <- ggplot(GLM_results, aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +  
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.2) +  
  coord_flip() +
  labs(x = "Cities",
       y = "Adjusted ORs with CIs") +
  theme_minimal()

GLM_plot
```

A noticeable trend in this plot is that most cities have ORs less than 1, suggesting that across these cities, homicides with male victims are generally less likely to be solved than those with female victims. Moreover, the CIs for the majority of cities cross the OR of 1, indicating that for many cities, the difference in the likelihood of solving homicides with male versus female victims is not statistically significant. Some cities have wide CIs, reflecting greater uncertainty in their estimates, while others have narrower CIs, indicating more precise estimates. 

## Problem 2

#### Weather data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

#### Bootstrap analysis for log_betas and r_squared
```{r}
fit0 <- lm(tmax ~ tmin + prcp, data = weather_df)
set.seed(123)
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

log_betas <-  
  bootstrap_results %>%
  group_by(strap_number) %>%
  summarise(log_betas = log(estimate[2] * estimate[3])) %>%
  select(log_betas, strap_number)

bootstrap_results2 <- 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

r_squared <- 
  bootstrap_results2 %>%
  select(r.squared, strap_number)
```

#### Fitting density plots of two estimates
```{r}
ggplot(r_squared, aes(x = r.squared)) + 
  geom_density() +
  labs(title = "Distribution of R-squared") +
  theme_minimal()

ggplot(log_betas, aes(x = log_betas)) + 
  geom_density() +
  labs(title = "Distribution of log(Beta1 * Beta2)") +
  theme_minimal()

r_squared_sd <-
  r_squared %>%
  summarise(r_squared_sd = sd(r.squared)) %>%
  pull(r_squared_sd)

r_squared_mean <-
  r_squared %>%
  summarise(r_squared_mean = mean(r.squared)) %>%
  pull(r_squared_mean)

log_betas_sd <- 
  log_betas %>%
  summarise(log_betas_sd = sd(as.numeric(log_betas),na.rm = TRUE)) %>%
  pull(log_betas_sd)

log_betas_mean <- 
  log_betas %>% 
  summarise(log_betas_mean = mean(as.numeric(log_betas), na.rm = TRUE)) %>%
  pull(log_betas_mean)
```

The $\hat{r}^2$ distribution is approximately normal, centered around a mean of **`r r_squared_mean`** with a narrow spread (SD = **`r r_squared_sd`**), reflecting a consistent model fit across bootstrap samples. In contrast, the distribution for $log(\beta_{1} * \beta_{2})$ is left-skewed with a mean of **`r log_betas_mean`** and a wider spread (SD = **`r log_betas_sd`**), indicating a tendency for the product of coefficients to be less than one and a more variable interaction effect between the predictors across samples.

#### Confidence intervals for  log(β^1∗β^2)
```{r}
CI_result <-
  log_betas %>%
  summarize(ci_lower = quantile(log_betas, 0.025, na.rm = TRUE),
            ci_upper = quantile(log_betas, 0.975, na.rm = TRUE))

CI_result_lower <- CI_result %>% pull(ci_lower)
CI_result_upper <- CI_result %>% pull(ci_upper)
```

95% Confidence Interval of $log(\beta_{1} * \beta_{2})$: (**`r CI_result_lower`**, **`r CI_result_upper`**)

#### Confidence intervals for r^2
```{r}
CI_result2 <-
  r_squared %>%
  summarize(ci_lower = quantile(r.squared, 0.025),
            ci_upper = quantile(r.squared, 0.975)) 

CI_result_lower2 <- CI_result2 %>% pull(ci_lower)
CI_result_upper2 <- CI_result2 %>% pull(ci_upper)
```

95% Confidence Interval of $\hat{r}^2$ : (**`r CI_result_lower2`**, **`r CI_result_upper2`**)

## Problem 3

#### Data Import
```{r}
birthweight_data <- read_csv("./data_file/birthweight.csv")
```

#### Tidying and wrangling the data
```{r}
cleaned_birthweight_data <-
  birthweight_data %>% 
  clean_names() %>%
  mutate(across(.cols = c(babysex, frace, malform, mrace), as.factor)) %>%
  mutate(babysex = ifelse(babysex == "1", "male","female"),
         malform = ifelse(malform == "0", "absent","present"),
         frace = recode(frace, "1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
         mrace = recode(mrace, "1" = "White", "2" = "Black", 
                        "3" = "Asian", "4" = "Puerto Rican", "8" = "Other")
         )
```

#### Checking Missing Values
```{r}
skimr::skim(cleaned_birthweight_data)
```

There is no missing data. The dimension of the birthweight data is `r nrow(cleaned_birthweight_data)` x `r ncol(cleaned_birthweight_data)`. The `r ncol(cleaned_birthweight_data)` variables include: *`r names(cleaned_birthweight_data)`.*

#### # Fit the initial model and Check the model summary
```{r}
initial_model <- lm(bwt ~ ., data = cleaned_birthweight_data)
summary(initial_model)
```

After fitting the initial model, the coefficients for babysex, bhead, blength, delwt, fincome, gaweeks, momage, mrace, parity, and smoken are significant at the 0.05 level. The NAs for pnumlbw, pnumsga, and wtgain suggest that there are issues with these variables in the model, such as multicollinearity.

Based on the provided coefficients and their p-values, I consider only the statistically significant continuous predictors for fitting a simplified linear model for birthweight. 

#### Proposing the Regression Model for Birthweight
```{r}
model_fit <- lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, data = cleaned_birthweight_data)

summary(model_fit) %>% 
  tidy() %>%
  select(term, estimate, p.value)

summary(model_fit) %>% 
  glance()
```

Based on the statistical summary, the fitted linear regression model with significant continuous variables—baby's head circumference, length at birth, mother's weight at delivery, gestational age, and smoking during pregnancy—explains 69.6% of the variability in birthweight (R-squared = 0.696). All variables are highly significant with strong associations to birthweight. 

#### Model Checking: Residuals Plot
```{r}
cleaned_birthweight_data %>%
  add_predictions(model_fit) %>%
  add_residuals(model_fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs Fitted Plot for Birthweight Model")
```

The "Residuals vs Fitted Plot" for the birthweight model indicates that the residuals are mostly randomly dispersed around the horizontal line at zero, which is good for homoscedasticity and linearity assumptions. However, the presence of a few outliers, particularly for higher fitted values, suggests that there might be some unusually large or small birthweights that the model does not predict well. There's no clear pattern indicating non-linearity or heteroscedasticity.

#### Computing rmse of models through cross validaiton
```{r}
set.seed(77)

cv_dataset <-
  cleaned_birthweight_data %>% 
  crossv_mc(n = 100,test = 0.2)
  

cv_df <- 
  cv_dataset %>%
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df <-
  cv_df %>%
    mutate(
    my_model  = map(train, ~lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, data = .x)),
    model_length_gaweeks = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_interactions  = map(train, ~lm(bwt ~ (bhead + blength + babysex)^3, data = .x))
    ) %>%
   mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
    rmse_length_gaweeks = map2_dbl(model_length_gaweeks, test, ~rmse(model = .x, data = .y)),
    rmse_interactions = map2_dbl(model_interactions, test, ~rmse(model = .x, data = .y))
   )
```

#### Fitting the distribution of rmse of the models
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot() +
  labs(title = 
  "Prediction Error Distributions across Models", 
       x = "Models", y = "Root Mean Square Error")  +
  scale_x_discrete(
    labels = c("My Model", "Length + Gestational Age", "Interactions Model")) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

Here, we are comparing models with respect to the cross-validated prediction error. By and large, my model seems to have the lowest prediction error (rmse) and hence is potentially the best model, followed by the Interactions Model and the Length + Gestational Age Model when comparing the medians (the line in the middle of the box) and the overall distribution of the box plots.
